---
title: Study 1--AI-Supported Learning Analysis for Teachers
date: 2025-08-05
categories: [TOP_CATEGORY, SUB_CATEGORY]
tags: [TAG]     # TAG names should always be lowercase
categories: [Wordinow, Research]
tags: [Research]
author: <author_id>        
description: Uptake, perceived value, alert–move alignment, workload trade-offs, fairness effects, and learning outcomes in Grade 5 English classes in Chinese public schools
---
<div style="text-align: justify;">

<h3>Introduction</h3>
<p>We set out to answer a pragmatic question with theoretical teeth. In a teacher-led adaptive English program, can an <strong style="color:#006400;">AI-supported learning analysis and alert system</strong> be both <strong style="color:#006400;">acceptable</strong> to teachers and <strong style="color:#006400;">instructionally effective</strong> in day-to-day lessons</p>
<p>The system is intentionally split into two capability clusters. First, <strong style="color:#006400;">data display and analysis</strong>. Its job is to surface evidence: mastery trends, subskill heatmaps, item difficulty, time on task, lexical coverage, and <strong style="color:#006400;">attentional-integrity indicators</strong> inferred from interaction traces. Second, <strong style="color:#006400;">suggestions, predictions, and alerts</strong>. This layer proposes next steps through teacher-ready <strong style="color:#006400;">action cards</strong>, a <strong style="color:#006400;">priority watchlist</strong>, and early warnings for rapid guessing, tab switching, irregular scrolling, bursty clicking, long post-prompt idle, and related patterns. Every alert explains <strong style="color:#006400;">why this alert</strong> and offers enactable responses and inquiry stems. In short, the first cluster shows; the second recommends.</p>
<p>All participating classes followed the same weekly cycle. Four sessions per week. Each session: <strong style="color:#006400;">30 system-selected target words</strong>, <strong style="color:#006400;">six short memory games</strong>, a passage embedding those words, <strong style="color:#006400;">reading-comprehension items</strong>, and a final vocabulary check with a brief comprehension probe. Analysis summaries flag whether words were learned reliably during games, decayed after reading, or never consolidated. Recommendations differentiate immediate restudy from <strong style="color:#006400;">Ebbinghaus-based SRS</strong> review. When vocabulary holds but comprehension collapses, the system suggests vocabulary-in-context mini-lessons, cohesion prompts, or background-knowledge checks. Alerts, in contrast, target regulation and the protection of engaged time.</p>

<h3>Research Questions</h3>
<p><strong style="color:#006400;">RQ1 Teacher willingness and real usage.</strong> After onboarding, how often and how persistently do teachers use the <strong style="color:#006400;">analytics panel</strong>, <strong style="color:#006400;">action cards</strong>, and <strong style="color:#006400;">priority watchlists</strong> in authentic lessons</p>
<p><strong style="color:#006400;">RQ2 Perceived decision support.</strong> Relative to circulation, dialogue, and <strong style="color:#006400;">basic charts</strong>, to what extent do teachers judge <strong style="color:#006400;">data display and analysis</strong> more helpful for fast and accurate decisions about individual pacing and mastery</p>
<p><strong style="color:#006400;">RQ3 Alert–move alignment and regulation.</strong> Do enacted moves match alert type — <strong style="color:#006400;">attentional-integrity disruption</strong> versus <strong style="color:#006400;">conceptual difficulty</strong> — and does this alignment predict regulation quality and subsequent achievement</p>
<p><strong style="color:#006400;">RQ4 Learning effectiveness.</strong> Compared with <strong style="color:#006400;">basic charts</strong> only, how does combined use of <strong style="color:#006400;">analytics</strong> and <strong style="color:#006400;">alerts</strong> affect cumulative <strong style="color:#006400;">vocabulary mastery</strong>, <strong style="color:#006400;">SRS-adjusted efficiency</strong>, and <strong style="color:#006400;">reading-comprehension</strong> gains over six weeks</p>

<h3>Methodology</h3>
<p>We used a mixed-methods, class-cluster randomized design across three public schools. Twelve Grade 5 classes were assigned to four arms. Quantitative models estimated intent-to-treat effects with cross-level interactions; qualitative work coded <strong style="color:#006400;">orchestration moves</strong> from sampled video and analyzed teacher reflections about usefulness and explainability. Teachers were encouraged — not compelled — to act on alerts; we logged <strong style="color:#006400;">reaction latency</strong> so timing could be modeled as a mediator. This choice preserves ecological validity while allowing causal contrasts.</p>

<h3>Theoretical Framework</h3>
<p><strong style="color:#006400;">Teacher noticing and professional vision.</strong> Evidence helps teachers notice; rationales help them interpret; moves enact interpretation.</p>
<p><strong style="color:#006400;">Actionable learning analytics.</strong> Visuals gain value when directly linked to <strong style="color:#006400;">action cards</strong> and time-bounded next steps.</p>
<p><strong style="color:#006400;">Classroom orchestration and self-regulation.</strong> Attention alerts call for regulation moves; conceptual alerts call for content moves. Conflating the two wastes time.</p>
<p><strong style="color:#006400;">Equity and explainability.</strong> Transparent <strong style="color:#006400;">why</strong> explanations and dignity-preserving language support trust, especially for quiet strugglers who are easy to overlook.</p>
<p><strong style="color:#006400;">Integrative model.</strong> The study operationalizes a pipeline from noticing to action. <strong style="color:#006400;">Analytics</strong> structures noticing. <strong style="color:#006400;">Professional vision</strong> anchors interpretation. <strong style="color:#006400;">Orchestration</strong> provides families of moves commensurate with problem type. <strong style="color:#006400;">Equity with explainability</strong> governs how evidence is surfaced. The predicted mechanism is straightforward: stronger coupling among these layers produces higher <strong style="color:#006400;">alert–move alignment</strong> and better learning.</p>

<h3>Hypotheses</h3>
<p><strong style="color:#006400;">H1 Use and persistence.</strong> Teachers sustain frequent use of <strong style="color:#006400;">analytics</strong> and <strong style="color:#006400;">alerts</strong> in routine practice.</p>
<p><strong style="color:#006400;">H2 Perceived decision support.</strong> Teachers with the <strong style="color:#006400;">analysis cluster</strong> rate decision support higher than teachers with <strong style="color:#006400;">basic charts</strong> only.</p>
<p><strong style="color:#006400;">H3 Alignment effectiveness.</strong> Regulation moves following attention alerts reduce off-task signals more than content reteaching in the same window; content moves following conceptual alerts improve accuracy more than regulation moves. A higher <strong style="color:#006400;">alignment index</strong> predicts achievement.</p>
<p><strong style="color:#006400;">H4 Learning effectiveness.</strong> Combined use of <strong style="color:#006400;">analytics</strong> and <strong style="color:#006400;">alerts</strong> improves vocabulary mastery, <strong style="color:#006400;">SRS-adjusted efficiency</strong>, and reading gains versus <strong style="color:#006400;">basic charts</strong> only.</p>

<h3>Data Collection</h3>
<p><strong style="color:#006400;">Sites and sample.</strong> Three public schools, four classes each, <strong style="color:#006400;">12 classes</strong> total, approximately <strong style="color:#006400;">20 students per class</strong>. Teachers varied in data-informed teaching experience.</p>
<p><strong style="color:#006400;">Teacher moderators.</strong> Baseline <strong style="color:#006400;">data literacy</strong>, <strong style="color:#006400;">technology acceptance or anxiety</strong>, and <strong style="color:#006400;">trust in AI</strong>, measured with short validated scales, used as moderators.</p>
<p><strong style="color:#006400;">Learning traces.</strong> Item accuracy and latency, hint use, retries, answer revisions, reading time, back-scrolls, evidence highlights, justification notes, cross-phase transfer signals.</p>
<p><strong style="color:#006400;">Attentional-integrity signals.</strong> Rapid-guessing flags by time thresholds, tab or window focus changes, scroll entropy, bursty clicks, idle after prompts, latency anomalies, repeated rapid answer changes, atypical keystroke pauses, and audio toggles where enabled.</p>
<p><strong style="color:#006400;">Analytics usage.</strong> Panel opens, dwell time, filters, cohort toggles, drill-downs, <strong style="color:#006400;">why</strong> views, action-card selections, and action logs.</p>
<p><strong style="color:#006400;">Orchestration moves.</strong> Sampled lessons double-coded for regulation moves, content micro-lessons, regrouping, conferencing, assessment prompts; κ ≥ 0.75.</p>
<p><strong style="color:#006400;">Assessments.</strong> Equated vocabulary and reading assessments at pretest and endline; outcomes include <strong style="color:#006400;">total vocabulary correct rate</strong>, <strong style="color:#006400;">SRS-adjusted efficiency</strong>, and reading accuracy.</p>
<p><strong style="color:#006400;">Teacher surveys and reflections.</strong> Biweekly usefulness, explainability, workload, and open reflections capturing moments when analytics confirmed or challenged intuition.</p>

<h3>Experimental Design</h3>
<p>Class-level cluster randomization assigned four classes to each arm.</p>
<p><strong style="color:#006400;">Arm A</strong> analytics and alerts. Full <strong style="color:#006400;">data display and analysis</strong> plus <strong style="color:#006400;">suggestions, predictions, and alerts</strong> with <strong style="color:#006400;">action cards</strong> and <strong style="color:#006400;">why this alert</strong>.</p>
<p><strong style="color:#006400;">Arm B</strong> analytics only. Full analysis cluster without alerts or action cards.</p>
<p><strong style="color:#006400;">Arm C</strong> alerts only. Alerts with explanations and action cards, paired with <strong style="color:#006400;">basic charts</strong> for performance.</p>
<p><strong style="color:#006400;">Arm D</strong> control with <strong style="color:#006400;">basic charts</strong> only. Minimal information by design: class mean accuracy, item counts, and a flat list of student total scores. No heatmaps, difficulty profiles, lexical coverage, attentional-integrity, or trajectory comparisons.</p>
<p>All classes used the same content and weekly routine. Teachers received a one-hour onboarding. Reactions to alerts were encouraged when appropriate; the system logged reaction latency.</p>

<h3>Data Analysis</h3>
<p><strong style="color:#006400;">Achievement models.</strong> Two-level hierarchical linear models compared Arms A, B, and C to D on vocabulary mastery, <strong style="color:#006400;">SRS-adjusted efficiency</strong>, and reading gains, adjusting for pretest and class random intercepts. Teacher <strong style="color:#006400;">data literacy</strong>, <strong style="color:#006400;">technology acceptance</strong>, and <strong style="color:#006400;">AI trust</strong> entered as moderators.</p>
<p><strong style="color:#006400;">Behavioral regulation.</strong> Difference-in-differences at the lesson level estimated changes in rapid guessing, tab switching, and idle-after-prompt rates across arms with class fixed effects.</p>
<p><strong style="color:#006400;">Alignment analysis.</strong> A <strong style="color:#006400;">move–alert alignment index</strong> increased when regulation followed attention alerts and when content moves followed conceptual alerts. We tested whether alignment predicted same-lesson normalization of off-task signals and endline outcomes, controlling for move count and minutes available.</p>
<p><strong style="color:#006400;">Workload models.</strong> Mixed-effects models related <strong style="color:#006400;">panel dwell time</strong> to perceived workload and outcomes, probing diminishing returns and an optimal dwell band.</p>
<p><strong style="color:#006400;">Distributional effects.</strong> Subgroup models estimated effects by baseline quartiles with <strong style="color:#006400;">Cohen’s d</strong> reported for low, mid, and high groups. Multiplicity was controlled using Benjamini–Hochberg; sensitivity checks varied rapid-guess thresholds and alignment weights.</p>

<h3>Implementation Notes</h3>
<p>The interface privileges <strong style="color:#006400;">interpretability</strong> and <strong style="color:#006400;">humane language</strong>. Teachers filter watchlists by severity or recency, pin preferred moves, and export action logs for reflection. Attention signals remain teacher-only to preserve dignity. Every analytic insight links to a compact next step sized for typical lesson constraints.</p>

<h3>Results</h3>
<p><strong style="color:#006400;">Uptake.</strong> Arm A teachers opened analytics or alerts in 88 percent of lessons; median dwell 7.6 minutes; action cards enacted in 63 percent. Arm B analytics opened in 81 percent; dwell 6.4 minutes. Arm C action cards enacted in 52 percent with minimal charting. Arm D charts viewed in 49 percent; dwell 3.1 minutes.</p>
<p><strong style="color:#006400;">Perceived decision support.</strong> Teachers in Arms A and B rated analysis as more useful than basic charts for rapid differentiation and mastery judgments. Typical reflections included “the decay after reading would have fooled me without the plot” and “quiet strugglers surfaced on the heatmap.” Notably, several reported productive moments when analytics challenged initial intuition.</p>
<p><strong style="color:#006400;">Alignment and regulation.</strong> Regulation moves after attention alerts reduced rapid guessing and tab switching more than content reteaching in the same window; content moves after conceptual alerts improved accuracy more than regulation moves. The <strong style="color:#006400;">alignment index</strong> predicted endline vocabulary and reading outcomes, independent of move count and minutes available.</p>
<p><strong style="color:#006400;">Learning outcomes.</strong> Relative to Arm D, Arm A achieved higher total vocabulary correct rate and higher <strong style="color:#006400;">SRS-adjusted efficiency</strong>; effects were largest for the lower baseline quartile. Reading gains were also larger in Arm A. Arm B outperformed D on vocabulary outcomes with moderate reading advantages. Arm C improved attentional integrity and indirectly supported learning, though magnitudes were smaller than A.</p>
<p><strong style="color:#006400;">Workload trade-offs.</strong> Dwell time showed diminishing returns beyond roughly nine minutes, where perceived workload rose as outcome gains flattened. An optimal band appears to be five to eight minutes.</p>

<h3>Discussion and Implications</h3>
<p>Separating <strong style="color:#006400;">data display and analysis</strong> from <strong style="color:#006400;">suggestions, predictions, and alerts</strong> matters. Analytics sharpen pacing and mastery decisions beyond what basic charts support; alerts improve regulation when matched to problem type. Transparent <strong style="color:#006400;">why</strong> explanations help build trust and speed enactment. Effects concentrate among lower baseline students, suggesting an equity benefit mediated by earlier detection and targeted reteaching. At the same time, a caution: over-reading dashboards can create cognitive drag. Professional learning should emphasize fast interpretation moves, not exhaustive tours.</p>

<h3>Limitations</h3>
<p><strong style="color:#006400;">Context specificity.</strong> Findings come from large Grade 5 classes in Chinese public schools; transfer to smaller, high-autonomy settings may require lighter visual granularity and fewer alerts.</p>
<p><strong style="color:#006400;">Time window.</strong> Six weeks capture short to medium-term effects and may understate trajectories in <strong style="color:#006400;">AI trust</strong>, data practices, and student self-regulation.</p>
<p><strong style="color:#006400;">Action discretion.</strong> Teachers could ignore alerts and prioritize moves; this preserves ecological realism but adds variance that likely attenuates average effects.</p>

<h3>Future Research Directions</h3>
<p><strong style="color:#006400;">Replication in high-autonomy contexts.</strong> Calibrate minimalist dashboards and sparse alerts in smaller classes with greater teacher latitude.</p>
<p><strong style="color:#006400;">Longitudinal dynamics of AI trust.</strong> Track how trust and <strong style="color:#006400;">alignment</strong> evolve over semesters as teachers internalize fast interpretation routines.</p>
<p><strong style="color:#006400;">Multimodal analytics.</strong> Explore privacy-preserving, camera-free proxies and securely consented modalities to refine <strong style="color:#006400;">attentional-integrity</strong> inference.</p>
<p><strong style="color:#006400;">Causal mediation by alignment.</strong> Manipulate action-card availability and explanation strength to test whether improved <strong style="color:#006400;">alert–move alignment</strong> mediates learning gains.</p>

<h3>Privacy, Ethics, and Training</h3>
<p>Student identifiers are pseudonymized; access is role-based; attention signals are teacher-only; logs are retained briefly. Training emphasizes <strong style="color:#006400;">dignity-preserving</strong> language and framing alerts as opportunities for support rather than surveillance.</p>

</div>
